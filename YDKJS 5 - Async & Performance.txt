===========================================Chapter 1===========================================
Asynchrony: Now & Later

-A Program In Chunks-
A JS program consists of several chunks, with some chunks running in the "present", and the rest running "later". A common type of a chunk unit is a function.
Asynchronous tasks do not block until completion, whereas synchronous tasks do. Ajax requests complete asynchronously. Requests are made in the present and the results are returned later.
The simplest way to block and wait from now until later when a return is recieved is to use a callback function.
While it is possible to make Ajax requests synchronously, it locks the browser UI, preventing user interaction. It is best avoided.
"Later" (asynchronous) code chunks are often functions that are set to run as a response to specific circumstances (timer or click event, Ajax response, etc).

-Async Console-
Until ES6, all asynchrony in JS was actually handled by the hosting environment. The JS engine would merely run the code chunk it was given. Hosting environments themselves were engineered to handle multiple chunks of JS code (and return their values), executing them over time, in accordance with their internal event loop. This means the surrounding environment is what has traditionally handled all event scheduling.
When making an Ajax request to fetch data from a server, you would set up a response code in a function (referred to as a "callback"). The JS engine suspends the execution and sends instruction to the hosting environment to suspend execution of the response function until completion of the network request, essentially requesting it "call" the function "back" once it retrieves (or fails to retrieve) the appropriate data. The browser itself listens for a response from the network, then schedules the execution of the callback function by inserting it into its event loop.
Each iteration of this callback event loop is called a "tick". During each tick, the loop checks if an event is waiting on the queue. If so, it is removed from the queue and the chunk is executed by running the function callback within the JS engine.
`setTimeout(..)` doesn't directly put your callback on the event loop queue. It sets a timer that, once expired, places the provided callback into the event loop for a future tick of the loop to execute. Even events not a part of your program can be added onto the hosting environment's queue loop as well. This is why the functions you pass it don't always fire with perfect accuracy.
As of ES6, the loop queue is now within scope of the JS engine in addition to the standard hosting environment accessibility/management. The primary reason for widening the breadth of control is for the usage of ES6's Promises, which require direct and specific control over event scheduling.

-Parallel Threading-
While async refers to the gap between now and later (scheduled and ran in serial), parallelism is about simultaneous execution.
Parallel computing commonly utilizes processes and threads, with both executing simultaneously and independently, but threads have the ability to share the memory of a single process.
Both parallel and serial can occur in tandem via the use of event loops in different threads working together.
The use of threaded programming is challenging, as you can run into trouble in situations where the same variables or registers in memory are being modified and used by multiple threads at the same time. While JS doesn't share data across threads, even simple things such as the sequence of threads can cause issues, or confusion at the least.

-Run-to-Completion-
JS is single-threaded, so functions run through to completion before running the next. This is known as "run-to-completion" behavior.
If viewed from the perspective of function/event-ordering level, a global chunk could be considered synchronous as it "happens now" and any function chunks (that aren't immediately invoked at the beginning of global (recall they aren't hoisted)) could be considered asynchronous as they "happen later". While there is still a degree of nondeterminism involved, this is more determinable than threads that introduce a variable level of statement and expression operation ordering.
Function-ordering nondeterminism when applied to the behavior of JS is referred to as "race condition", as multiple functions are "racing" to see which condition plays out, adding a degree of unreliability to the result.
Generators are functions that do not have your typical run-to-completion behavior.

-Concurrency-
When appending to a list of updates on a page upon scrolling down, you are executing at least two (virtual) procesess/tasks simultaneously (*roughly* at the same time, rather than instantaneously). The first is a response to the appropriate `onscroll` event firing, resulting in an Ajax request for more content. The second is to display the content once a response is received from the Ajax request.
Whether these operations occur in parallel or not, the simultaneous ***execution*** of multiple processes over the same period is regarded under the label of "concurrency". Consider it to be "process" or task-level parallelism, rather than operational/threaded.
With the previous example, it is possible that both an `onscroll`-triggering Ajax request is made and a response from an entirely different request is received and executed at roughly the same time. Keep in mind, though, that only one event can be executed in the JS engine at a time, so they must first be interleaved into the hosting environment's event queue and sequentially fed to the engine. The processes only run concurrently at task-level, with the events scheduled and executed in a one at a time, single-threaded manner.

-Noninteracting-
Nondeterminism is not an issue if these concurrently virtual processes/tasks you are interleaving into the event queue are unrelated and don't interact with each other.
If the concurrent processes will work as intended, regardless of its ordering, this would not be considered a race condition bug.

-Interaction-
Concurrent processes will interact more commonly than not. Always remedy race condition nondeterminism via value sharing in scopes by delineating different potential responses in your callbacks, checking that all necessary conditions are met/completed (especially those from other processes). You may also need to ensure you are carving out separate spaces for any response data to be stored (such as storing one specific type of response in one array slot, adding another to a different slot, etc), in order to maintain proper coordination of ordering interaction.
`if` statements that aren't ran until a `true` return of conditional checks for values that won't be set until the completion of callbacks are referred to as "gates".
A "latch" (sometimes called a "race"), is a nondeterministic concurrency interaction that is explicitly designed to only allow for callback execution of the first process to complete.

-Cooperation-
Cooperative concurrency is the act of taking longer processes and batching them out, allowing for room to interleave the operations of other processes into the event loop.
For example, if a resposne for one process is received that then runs a callback mapping several million values onto an array, everything else (other processes, UI updates, user events) will be unresponsive and unable to update. Instead, you can process such a large amount of results by breaking them up into smaller asynchronous batch operations that process after each one yields back to the event loop, effectively allowing other waiting events to occur before running the next batch, which results in a more performant site/app.
This can be done using the `setTimeout(.., 0)` hack, which is a simple way to have the timer asynchronously schedule the referenced function at the end of the event loop queue as soon as it can. Node.js uses a similar `process.nextTick(..)`.
As of the writing of the book, there is no single direct way to ensure the ordering of async events across all environments.
Cooperation can also be combined with concurrent interaction ordering techniques when necessary.

-Jobs-
The job queue, a new addition in ES6, is another layer added on top of the event loop queue that is mostly (indirectly) exposed via the use of Promises.
One way to conceptualize the job queue is that it exists at the end of every tick in the event loop queue. Some async actions arising during an event loop queue tick may not be added to the end of that queue, but rather to the job queue at the end of that tick as a job, intended to run immediately after that tick.
A job can result in the addition to more jobs at the end of the same job queue.
Jobs allow for somewhat more defined and guaranteed ordering. Similar to the `setTimeout(.., 0)` hack, but scheduled at the end of the current event tick, rather than at the end of the entire event queue loop.

-Statement Ordering-
Compiler statement reordering will never reorder or combine statements in a way that will create observable side effects, only performing safe optimizations.
Although altered statement ordering has no observable impact, it is best to remember that code is not always compiled to run in the top-down fashion in which it is written, instead being constantly restructured by the compiler to run in more of a concurrent and interacting fashion, not dissimilar from the flow of async code.

-Review-
JS code is broken into multiple chunks of code, the first of which runs "now", and the latter which runs "later" (as a response to an event). These chunks share scope and state.
User interaction, I/O, and timers can all add events to the event queue. Only one event from the queue can process at a time.
Concurrency is when multiple chains of events (known as processes or tasks) are woven together on the event loop, appearing to run simultaneously. 
Interaction coordination between concurrent processes is often required to guarantee precise ordering or prevent unwanted race conditions that could cause unpredictable results.
You can also break large processes into smaller chunks to allow cooperation and cohabitation with other various processes, I/O, and rendering that may be a part of the event queue as well.

===========================================Chapter 2===========================================
Callbacks

Callbacks are the most common and fundamental pattern of asynchrony that occur in JavaScript.

-Continuations-
Callback functions wrap or encapsulate the continuation of a program.

-Sequential Brain-
The human brain works similarly to the event loop queue via concurrent single-tasking.

-Doing Versus Planning-
While we think in step-by-step behaviors, callbacks are not expressed in such a (sequential) manner when moving to asynchrony.

-Nested/Chained Callbacks-
Nested callbacks are often referred to as "callback hell" or the "pyramid of doom", due to their confusing combination of nesting and lack of easily readable ordering when using async function calls.
Author points out that nesting really has little to do with the difficult readability, but moreso the unsequential nature of function execution when using async callbacks. This becomes even more confusing once you begin manually hardcoding alternate conditional paths, error handling forks, simultaneous callbacks, branches into parallel (concurrent) callbacks, etc.

-Trust Issues-
Callback-driven code and its lack of mirroring to the sequential brain are a part of confusing aspects of async, but inversion of control is a much deeper and ambiguous occurence.
Because you are usually handing off your callback functions to a third-party utility or a method you did not write or directly control, expectations for how/if a return is made may not always be clearly defined.

-Tale of Five Callbacks-
A lot of things can potentially go wrong with third-party API utilities that employ the use of async callbacks.
These include receiving multiple (unintended) callback responses for a single request, a lack of or late intended response, an early callback response, a lack of or incompatible return parameters passed to the callback, or disappearing errors/exceptions.
If you aren't positive that you can trust a utility to handle your async callbacks, you would have to add handle every single situation that could potentially go awry.

-Not Just Others' Code-
While the use of versioned APIs or self-hosted libraries can help remove much ambiguity and potential for mishap, you should still add checks and normalizations for your async code.
This introduces a lot of boilerplate or overhead code that needs to be repeated for each async callback.

-Trying to Save Callbacks-
Some APIs are designed to offer split callbacks for both success and failure conditions. This pattern is what the ES6 Promise API uses. 
Another callback pattern is the error-first or Node style. If successful, the first returned argument will be falsy or an empty object.
These designs still don't deal with that majority of the previously outlined trust issues that can occur. It also introduces the additional potential problem returns where you receive both error and success objects at once, or nothing at all for each argument. This means your boilerplate surrounding each callback is going to need to be even more verbose.
You can write a timeout function that cancels the event after the specified amount of time passes, pass your callback into that as an argument (to be executed), and then pass that function into your async call in place of the callback function.
In scenarios where it is possible that a callback could be invoked synchronously (such as with a pre-cached url), it is always best to still add it to the event loop to be asynchronously returned later, as not doing so can introduce unpredictability and bugs in places there is still remaining code to be executed. The order of execution would essentially become dependent upon the synch/asynchronicity of the callback.
You can convert a potentially synchronous callback to an async one by passing it to a utility function that checks if a `setTimeout(..)` of 0 (adds to end of event loop) has completed. If it completes first, it just passes the callback function as is. If not, the returned callback that was passed into the utility will return once the `setTimeout(..)` interval has completed (essentially completing at least one asynch tick).

===========================================Chapter 3===========================================
Promises

The idea of Promises is that, rather than inverting control of the continuation of your program over to a third party in hopes that it will correctly invoke your callback, you expect a return letting you know when that third party API has finished its task so that your code can then decide what to do next.
Most new async APIs are being designed to make use of Promises.
"Immediately", in regards to Promises, is usually used when referring to Job queue behavior, rather than the synchronous "now".

-What Is a Promise?: Future Value-
One way to think of a Promise is as a receipt for a future value which you have no yet received. It represents a time-independent future value.
Once the future value is ready, you exchange the value promise for it. You may also receive an indication that no value will be availed, in the form of a failure.
Lastly, you may be left with an unresolved state where the future value is never retrieved.

-Values Now and Later-
When working with callbacks, you know they won't be invoked until request results are later returned. But what if you are performing an operation that relies upon one or more returned callback values?
To consistently handle operands that may be either "now" or "later", you must make the entire operation async, either by manually checking/waiting for values to resolve, or some other mechanism.

-Promise Value-
Promises return values in the temporal, time-independent manner that is required when performing operations of uncertain synchronicity.
Promises can be created that resolve once an array of other promises have been successfully returned (by creating the promise with `Promise.all(..)`).
Chaining another call to it using the `.then(..)` call creates another promise. In its return, you can invoke a function that can be passed any return values from your initial promise invocation.
Promise rejection values, commonly referred to as "rejection reasons", can be set directly in the program or implicitly resulted via runtime error.
An error handler function can be directly added to a `.then` chained-call by adding it as the second parameter.
As Promises encapsulate time-dependent state, they can be used in a manner that is predictable and time-independent. Its return value becomes immutable and observable once resolved.

-Completion Event-
While one Promise can be equivalent to a future value, they can also function as a flow control mechanism within the scope of a larger sequence of asynchronous operations.
Classically, such situations call for listeners and events, so you can view this from the perspective of needing to listen for a completion or continuation event to be emitted by a particular function.
The term "completion event" is more related to the importance of the execution of a function finishing, compared to "continuation event", where the focus is more about being able to continue with the following steps in a sequence.
With Promises, you are essentially setting up two listeners, one for a success event and one for a failure event to be returned. You are only awaiting the final outcome of the event call. This contrasts callbacks, where the "notification" would be the execution of the callback function itself.
This means that Promises essentially separate the called function from the calling code's subscription to the completion/continuation events, with the called function's returned event being ran against the two event handlers. This uninverts the control previously inverted by callbacks.
With this level of separation of concerns, you can give multiple separate parts/functions in your code the capability to independently listen for return events from the same function.
The event object returned is basically a neutral third-party negotiation between separate, independent task entities.

-Promise "Events"-
Promise "events" don't strictly follow the format previously outlined, although they certainly behave in such a manner for these purposes. You use `.then(..)` to register a "then" event (either "fulfillment" or "rejection"), although you do not explicitly see them in code.
`new Promise( function(..){ .. } )` is generally referred to as a "revealing constructor". In it, the function passed in is executed immediately, rather than async deferred like with `.this(..)`. The function is provided with both a `resolve` and `reject` parameter, which are resolution functions for the Promise that signal success or failure.
Your resolution handler functions wait for completion of the Promise resolution function before flow control takes place (using `.then(..)`), which doesn't always necessitate a message being sent to it, as mere completion is sometimes the only thing to be required for continuation.
Chaining `then(..)`s results in a different pattern known as forking, versus semi-colon separated `then(..)` statements that results in a splitting behavior.
You can also use the promise itself in combination with `.then(..)` to control the execution of functions, the difference being that an explicit call of these handler functions means that they will always run, which may necessitate the need for error handling being included in the function, whereas `then(..)` allows you to directly specify an error handler as the second parameter.

-Thenable Duck Typing-
You can receive Promises from another window/iframe, which means that checking for an `instanceof` a Promise would result in a failure to identify. Some libraries/frameworks also use their own form of Promises that are unrelated to the built-in ES6 type.
The way to recognize a Promise or something conformant and Promise-like is by checking if it is "thenable", which is any object with a `then(..)` method on it.
Type checking that identifies based on the shape (properties that are present) of an object is referred to as "duck typing" ("looks like a duck, quacks like a duck, must be a duck").
Duck typing Promises can be problematic in situations that have the matching property name, but weren't intended to be treated as thenable Promises, or objects that inherit "then(..)" from their `[[Prototype]]`, that are also unintentionally recognized as Promises. Another circumstance (which is already a no-no as you shouldn't be adding properties to JS native prototypes) is the existence of an added `then(..)` property on the Array or Object prototypes, which would result in all arrays/objects being thenable. Several pre-ES6 non-Promise libraries exist that possess `then(..)` methods.
Regardless of the poor standard chosen for identifying Promises, duck typing are still said to be helpful when caution is taken.

-Promise Trust-
Promises are designed to resolve all inversion of control issues outlined with the use of callbacks in the previous chapter.

-Calling Too Early-
Promises, by definition, cannot be subjected to race conditions. Even immediately fulfilled Promises are only capable of being ***observed*** asynchronously, as callbacks provided to `then(..)` cannot be called synchronously.

-Calling Too Late-
A Promise's `then(..)` observation callbacks are automatically scheduled (in order) upon the calling of `resolve(..)` or `reject(..)` by the Promise. They will be predictably fired at the end of the current asynchronous "tick" as Jobs. These registered callbacks cannot affect the calling of any the proceeding `then(..)` callbacks.
This means that embedding `then(..)` callbacks inside of other callbacks will still result in all `then(..)` callbacks from the enclosing scope being scheduled first, in sequence.

-Promise Scheduling Quirks-
There are some nuances where `then(..)` returns don't appear be properly sequenced.
One example is when creating a Promise that awaits the resolution of another Promise in the same enclosing scope before its own resolution. Since you are essentially "unwrapping" another Promise asynchronously (you have to wait for the enclosed value to resolve), the "wrapper" Promise is added to the end of the asynchronous Job queue, after any remaining callbacks have completed (including the remainder in the same enclosed scope).
Because of such nuances, it is best to code in a way that the ordering or scheduling of multiple Promise callbacks are depended upon.

-Never Calling the Callback-
Nothing, including JS errors, can prevent a Promise from returning its resolution, as long as fulfillment/rejection callbacks are registered. Even callback errors themselves don't get swallowed, and the callback is still always ran.
Promises themselves possess a "race" method that provides a means to return a rejection callback (with an error specifying the reason) when a call doesn't asynchronously resolve in the specified time. This means, you do not need to worry about a Promise ever causing your program to hang indefinitely.

-Calling Too Few or Too Many Times-
Too few is best defined as not calling at all, as the correct amount of times for a callback to be called is once.
Promises are defined to only be resolved once, with that resolution value being treated as immutable. All subsequent attempts are silently ignored. This also means that any `then(..)` registered callbacks will be called a single time as well (for each time it exists in your code).

-Failing to Pass Along Any Parameters/Environment-
If the return value for a Promise is not explicitly returned, it will be `undefined` and still be passed to all registered callbacks.
All parameters beyond the first that are passed in `resolve(..)` or `reject(..)` will be silently ignored. This is because the use of multiple parameters in a resolution value are not valid usage of the Promise mechanism. You must wrap multiple values in a single `array` or `object`. Similar behavior applies to invalid actions such as calling `resolve(..)` more than once.
Just like JS functions, Promise callbacks retain access to the enclosing scope in which they are defined.

-Swallowing Any Errors/Exceptions-
Rejection reason values are passed to rejection callbacks.
`TypeError`s and `ReferenceError`s that occur during the creation or observation of a Promise will be returned in its `rejection(..)` value in the form of a catchable error object.
This behavior has the additional benefit of rendering errors within Promises as asynchronous occurences, allowing for the continued maintenance of sequential predictability.
Recall that `then(..)` calls return another Promise, so if your error only occurs during observation, it's that new Promise that will be rejected. It cannot use its own handler to call a rejection because that is specifically for the Promise that it is observing (which in this example, was fulfilled with a non-rejection return value), and Promises are immutable once resolved.

-Trustable Promise?-
Promises don't get rid of callbacks, but rather change them from being passed to a function to be executed upon receiving a return response, to receiving something back from a function return (such as a genuine Promise) and then passing the callback to that.
To ensure the trustability of whatever you receive back from your function return is a genuine Promise, you can use the `Promise.resolve(..)` utility.
Passing an immediate, non-Promise value to `Promise.resolve(..)` will return a genuine promise that is fulfilled with that value.
Passing a genuine, thenable Promise value to `Promise.resolve(..)` returns the same promise back.
Passing a non-Promise, but thenable value to `Promise.resolve(..)` will result in the utility attempting to unwrap the value continually until a final, non-Promise-like value results, and then return a genuine promise that is fulfilled with that value.
This helps for filtering untrustworthy and potentially thenable non-Promise values, unwrapping them if need be, and returning them wrapped in a normalized and trustworthy Promise to be asynchronously chained/observed off of.

-Trust Built-
Promises are a pattern that augments that already-established use of callbacks with trustable semantics that allow for more reasonable and reliable behavior.
They effectively uninvert the inversion of control caused by callback usage, and place it into a trustable system designed specifically for the readability, robustness, and maintainability of asynchronous code.

-Chain Flow-
You can create an intermediate variable for each fulfilled value in a chain and call that variable with `then(..)`, or just chain your `then(..)` promises together to have the each promise's return value passed to its proceeding and automatically-created promise.
Just as `Promise.resolve(..)` automatically unwraps recursively to get to the final value of a thenable, the same behavior occurs when returning a thenable or Promise from either a fulfillment or rejection handler. This means that you can return a new Promise from a chained `.then(..)` Promise, and the subsequently-chained `.then(..)` will call its function once the Promise it was passed asynchronously completes and returns an unwrapped value. Using this, you can construct sequences containing as many asynchronous steps as needed.
Return values are not necessary when `then(..)`-chaining, as `undefined` will still be returned without an explicit `return` statement. The Promise resolution itself is the signal to proceed to the following step in the chain.
The Promise mechanism automatically combines the states of both a returned Promise and the Promise that is returning it, so you can think of the returned Promise as a replacement for the previously-returned chained Promise that enclosed the return.
One practical example of chaining Promises in this manner is to make an ajax request async-aware by returning a Promise, and use it to construct a URL using a response from an initial http request using the `request(..)` method, which would return a Promise containing a response message to be used in the subsequent URL construction. You'd follow that step in the async flow control chain up with a final step that waits for the second ajax call to complete. This acts as both a flow control and pushes relevant response messages to subsequent links in the chain with each step.
When an error is encountered in one of the steps of an async sequence, it will return a `rejection(..)` function, that can be handled by the subsequent step, whose handler can even return a fulfillment from the promise for the next step to receive, if it's set up that way, putting the chain back into a state of fulfillment.
If a `then(..)` only contains a fulfillment error, a rejection handler will be substituted in that will rethrow the same error that was passed to it, effectively propagating the error along each step in the chain until an explicit error handler is discovered.
There is also a default fulfillment handler that is substituted into a `then(..)` step when a valid function is not passed in. It simply passes the received value along to the next step. A shortcut for this pattern is to use `catch(function(err){..})`.
If a fulfillment/rejection returns a Promise of its own, it is unwrapped and its resolution is then substituted in as the resolution for the chained Promise returned from the current `then(..)` in the chain.
A much better pattern for expressing sequential flow control in such a manner is via the use of generators.

-Terminology: Resolve, Fulfill, and Reject-
There is some confusion with the name of the first callback parameter of the `Promise(..)` constructor being "resolve", since resolution implies either fulfillment or rejection.
The `.resolve(..)` Promise API method will actually create a Promise that is resolved to the value passed to it, including non-Promise, non-thenable, and thenable values. These may actually resolve to rejected Promise values, in the case where it is passed a `Promise.reject(..)` value (which it then unwraps and passes as a rejected Promise).
This means that the first parameter in a Promise callback (in addition to unwrapping a genuine Promise) can also unwrap thenable values to reveal a rejected state, return a Promise with that same state.
`reject(..)` does not perform this same thenable unwrapping behavior. When passing such a value, that still-wrapped value will serve as the reason for the rejection. A rejection handler that followed would recieve that still-wrapped value.
The author suggests calling the callbacks provided to your subsequently-chained `.then(..)`s as `fulfilled(..)` and `rejected(..)`, as the first parameter passed to this method is unambiguously and always a fulfillment case, unlike with `Promise(..)` constructors. ES6 spec uses `onFulfilled(..)` and `onRejection(..)`, similarly.

-Error Handling-
`try..catch` is synchronous-only and is of no use in async patterns without additional environmental support.
The most notable callback error handling pattern is known as "error-first callback" style. It entails adding a conditional check for a first parameter, equal to either null an error value, into your callback, passing that callback into another function that asynchronously executes a `try..catch` block, which executes your callback and passes it an error if caught, or null for the first parameter and potentially a second value parameter if no errors were caught.
A downside is if function calls inside of the callback itself are async-completing, their errors will not be catchable.
Promises use split-callbacks, which are somewhat more difficult to grasp in certain situations, due to the fact that errors occurring inside of the fulfillment handlers can only be captured and notified from subsequent chain-linked `.then(..)` promises, seeing as the initial promise has already been fulfilled and is now immutably unable to "converted" to a rejected value.
Invalid use of the Promise API to construct a promise results in an exception error being thrown, rather than a rejected Promise, as it was never actually constructed.

-Pit of Despair-
Promise error handling is "pit of despair" by design -- where mistakes are punished, rather than having you default into a successful action. It assumes you want errors to be swallowed by default, unless explicitly observed.
While some developers will stick a `.catch(..)` on the end of an async chain as a means of overcoming this design and catching any errors as they filter down from any point in the chain, there is still a chance that the `.catch(..)` callback or even the promise that *it* returns could throw an uncatchable/uncaptured error.

-Uncaught Handling-
Some Promise libraries add methods for registering something such as a "global unhandled rejection" handler, which calls in place of a globally thrown error. These work by catching errors thrown within a arbitrary time limit after a Promise was rejected. While this works for most usage patterns, there are cases where the time delay does not catch the error, and where there are false positives in cases where you don't immediately register a handler and other "uncaught" errors occur in the interim.
Some developers suggest finishing each Promise chain with `.done(..)`, as it does not create or return a Promise, and throws any uncaught error conditions passed to it as global uncaught errors. Unfortunately, it is not a part of the ES6 standard, which means it lacks omnipresence and reliability.
Browser developer consoles will report any uncaught errors found during the garbage collection process, although the author states that this feature is not comprehensive. It's also possible that a Promise is not garbage collected accidentally through various coding patterns.

-Pit of Success-
The author suggests that Promises could default to reporting rejections to the dev console on the next Job or event tick if no error handler was registered for that Promise at that exact moment.
You could call `defer()` on a Promise to suppress this automatic error reporting in cases where you want it to hold onto its rejected state for an indefinite amount of time.
This would be considered a "pit of success", as the default behavior decreases the chances of not catching an error, rather than increasing the likelihood of such mistakes.

-Promise Patterns-
There are several async variation patterns you can use to build abstractions on top of the Promise mechanism. Two are built directly into the native ES6 Promise implementation.

-Promise.all([..])-
The `all([..])` pattern functions as a gate mechanism, allowing for multiple requests to be made concurrently, contrasting to the linear, sequential pattern of previous.
You pass it a single array containing (generally) Promise instances, but can also include thenable and immediate values (each will be implicitly passed through `.resolve(..)`). The Promise it returns will contain an array of fulfillment messages, presented in the same relative order as your initialization parameter array.
If any of the Promises in the `all([..])` array are rejected, the main Promise that it returns will also be rejected, eschewing results from the other Promises.

-Promise.race([..])-
This pattern, called a "race" with Promises, is classically referred to as a "latch". It works similarly to `.all([..])`, in that you provide it with multiple Promises or values to be `.resolve(..)`ed to Promises, but it diverges in that it returns a Promise that is either fulfilled or rejected based on the state of the first Promise to return.
Passing an empty array to `.race([..])` will result in a Promise that never resolves. This was implemented as a gotcha due to Promise libraries that predates ES6.
`race([..])` returns the single fulfillment value message of the Promise that won the "race", rather than an array.

-Timeout Race-
You can use `.race([..])` in a timeout pattern to ensure a Promise (or one of multiple) is only fulfilled if it resolves within a particular time frame.
You do this by passing the Promise that needs to be fulfilled within the time limit, along with your timeout function that automatically returns a rejected Promise once its set timeout elapses. Whichever one resolves first wins the race and shares the same state with `.race([..])`'s returned Promise.

-"Finally"-
With `.race([..])` and timeouts with Promises, the "losers" still exist as they cannot be cancelled, only silently ignored.
Some developers have proposed the need for a `finally(..)` callback registration to be automatically called upon each Promise resolution, allowing you to simply observe the resolution of Promise, specify any cleanup such as freeing reserved resources, or cancelling any side effects that a Promise may have had. This may come to be in ES7+.
You can create a static helper utility to be able to observe (but not interfere with) the resolution of such Promises. You'd essentially wrap your Promises in this utility function, also passing along any callback you'd like to use for cleanup or other purposes. Inside of the utility, you chain the Promise to a `.then(..)` link that checks the resolved value of the Promise and acts accordingly (calling your callback and passing it the resolution message to clean up, log to console, etc.), followed by returning the initial Promise's resolution. You can use this wrapper utility in place of a direct Promise in a `race([..])` or `all([..])` parameter array.

-Variations on 'all([..])' and 'race([..])'-
Other commonly-used variations of these patterns are as follows...
`none([..])` is similar to `all([..])`, but all passed Promises need to be rejected in order for a fulfillment resolution to occur.
`any([..])` is similar in structure to `all([..])`, but only needs one of the passed Promises to be fulfilled in order for fulfillment resolution to occur.
`first([..])` is similar to `race([..])`, but ignores rejections and fulfills as soon as one of the passed Promises return a fulfillment.
`last([..])` is similar to `first([..])`, but the last fulfillment "wins".
Some Promise libraries provide these methods, but you can also add them yourself.

-Concurrent Iterations-
While you can iterate over a list of Promises and perform synchronous tasks, similarly to synchronous arrays (with `forEach(..)`, `map(..)`, etc.), you can use async versions of these utilities when performing asynchronous or concurrent tasks. These are provided by numerous async libraries.

-Promise API Recap-
There are spec-compliant native Promise polyfills available for pre-ES6 browsers.

-new Promise(..) Constructor-
The `Promise(..)` revealing constructor must be called with the `new` keyword, and also must be passed a function that is immediately synch invoked. It's passed two callbacks, usually named `resolve(..)` and `reject(..)` whose purpose is to provide resolution capability for the Promise.
`reject(..)` will reject the Promise when called, but `resolve(..)` can either fulfill the promise or also reject it, depending on what it was passed. Sometimes a thenable or genuine Promise is passed the `resolve(..)` callback, unwrapped, and then resolved to a rejection state, which is then adopted by enclosing Promise as its return value.

-Promise.resolve(..) and Promise.reject(..)-
`Promise.reject(..)` is simply a shortcut for creating an already-rejected Promise. It is equivalent to creating a new Promise using the revealing constructor and invoking the `reject(..)` callback within the Promise's immediately-invoked callback.
`Promise.resolve(..)` works similarly to its `Promise.reject(..)` counterpart, but also recursively "resolves" wrapped thenable values to get to a final "resolution" value that can be either a fulfillment or rejection, to be adopted and returned by the parent Promise. It simply directly returns values that are already genuine promise values.

-then(..) and catch(..)-
Every Promise instance has a `then(..)` and `catch(..)` method, allowing the registering of fulfillment/rejection handlers for it. Once the Promise resolves, one of these will be called as asynchronous Jobs.
`catch(..)` takes only one parameter for the rejection callback, always substituting a default fulfillment callback, similar to the one availed to a`then(..)` when it is passed a `null` value for its fulfillment callback.
These methods create and return a new Promise, allowing for Promise chain flow control. The Promise they return will be rejected if the fulfillment/reject callbacks threw an exception.

-Promise.all([..]) and Promise.race([..])-
`Promise.all([..])` functions as a gate, where all Promises passed to it must be fulfilled in order for the enclosing Promise to be fulfilled.
`Promise.race([..])` works as a latch, where the first to get through determines the enclosing Promise fulfillment/rejection value.
An empty array passed to `.all` will fulfill immediately, but one passed to `.race` will hang and never resolve.

-Promise Limitations: Sequence Error Handling-
Because a Promise chain is a sequence of Promises, with no way to refer to it as a single entity, there is no external way to observe errors that occur on it, necessitating the explicit addition of error handling.
Referencing the last promise in a chain (referencing an entire chain will always result in a reference to the last promise of that chain) can be enough for a chain that has no error handling in it, as errors propagate down the chain. You can just register an rejection handler in the last step, or even on the reference itself, to be notified of any errors that occur in the chain.
This only notifies you of unhandled errors, similar to how `try..catch` can catch and swallow up exceptions, which can be restrictive in certain cases.

-Single Value-
Promises can only be of a single fulfillment or rejection value/reason.
You can construct a wrapper, in the form of an object or array, to hold multiple values/messages, although having to wrap and unwrap these messages along the Promise chain can be a cumbersome exercise.

-Splitting Values-
You can split multiple messages into their own individual promise wrapper.
This does not do much to cut down on the verbosity of the syntax, but it does improve the ability to refactor and split those individual messages into separate functions for calculations and the like.
Splitting into promises rather than simple values in an object/array wrapper also allows for greater flexibility and cleanliness in using them with Promise helper methods.

-Unwrap/Spread Arguments-
You can minimize the overhead of having to manually assign your returned promise array messages by creating and using a spread utility (either inline or as a separate helper function). This utility sequentially "spreads" your array values across the parameters defined in the function you pass it, by use of `Function.apply.bind(..)`.
To break that down, `.bind` returns and calls a new function from `Function.apply` that is contextually `this`-bound to the function passed into the utility. This newly-bound function is essentially that same passed function, but appended with the `.apply(..)` method, so the Promise array argument (which was passed to your `this` function since this spread utility function is the fulfillment parameter for a `.then` Promise chain step) is converted into individual arguments, and then applied in sequence to the parameters specified by the `this`-bound function that was passed into the spread utility.
ES6 can actually perform this utility for you via usage of destructuring assignment. You simply declare your variables sequentially on the left-hand side of the assignment using array syntax, and then add the value to be unpacked into this destructured assignment on the right-hand side. This can even be done as an array parameter, which leads to very minimal, readable code.

-Single Resolution-
Promises don't work well in an event or stream model where multiple instances of value resolution may occur, since a Promise can only resolve once.
You can invert the sequential Promise design pattern, putting your async chain inside of your event handler, so that a new chain is created each time your event triggers. This can be awkward to do though in situations where you want to seperate your concerns further, such as dividing up your event response from your event handler.

-Inertia-
ES6 does not include a native means to easily convert callback-expecting functions into Promise-aware functions, although such a wrapper is availed in numerous Promise libraries and easily writeable by oneself.
A Promise wrapper function for a callback-expection function works by taking a function that expects to receive a callback as its last parameter, and returning a new function that creates a Promise to return. This Promise substitutes the original callback parameter with one wired for Promise fulfillment/rejection.
Since this does not produce a Promise itself, but rather a function that creates Promises, the author suggests this should be called "promisory wrapping" and the resultant function a "promisory". The act of wrapping a function in this way is also sometimes referred to as "lifting" or "promisifying".
With this utility, you can maintain your callback-based code for compatibility with other parts of code, if need be, or modify them to use your new promisory.

-Promise Uncancelable-
Some Promise libraries provide the capability to externally cancel Promises, but this goes against future value trustability/external immutability and fits the "action at a distance" anti-pattern, which leads to similar frustrations that were found when just using callbacks.
Since you cannot stop a Promise from resolving itself once it is created and registered with handlers, you can add conditionals flags/checks to your resolution callbacks that either prevent or allow the further execution of code further down that or other Promise chains (such as in a race condition). This is best avoidable though, as it is both verbose and, at that point, best left to a higher level of abstraction (such as a cancellation method in a Promise library).
It is of little value to cancel a single Promise, but can be handy with a chain of multiple Promises since they represent a flow control expression that is appropriate for cancellation, especially seeing as an entire sequence is not itself equivalent to a single immutable value.

-Promise Performance-
Promises are slightly slower than using a basic callback-based async task, although the layer of guards and additional work provided by Promises makes the difference in comparison difficult to justify.
The always-async aspect of Promises may also degrade speed slightly over basic callback usage.
Author opines that Promises should always be the default choice over basic callbacks, as they are far superior, regardless of slight loss in speed, since they help to ensure trustability, avoid Zalgo unpredictability (race conditions), and composability.

-Review-
Promises don't get rid of callbacks, they just redirect their execution to a trustable mechanism that lies in-between our code and another utility, resolving the inversion of control issues that taint the use of just using callbacks.
They create a better way of addressing asynchronous code in a human, sequential fashion, although there is a better solution to that matter.

===========================================Chapter 4===========================================
Generators

-Breaking Run-to-Completion-
Generators are a new ES6 function type that do not possess the typical run-to-completion behavior. They start and stop one or multiple times and don't need to finish.
JS is not a pre-emptive or (presently) multithreaded language, so a particular call statement that is not present in a function cannot simply interrupt and run exactly between two statements. Instead, a cooperative form of such an interruption, called cooperative concurrency, is made possible when used in "cooperation" with an iterator and the `yield` keyword to indicate a pause at a particular point in code.
You can declare generator functions as `function* foo(){..}`, `function*foo(){..}`, or `function *foo(){..}`. The author recommends the latter because it is the easiest form to use when searching for a specific generator.

-Input and Output-
When assigning a generator to a variable, you are not actually invoking that function, even though the right-hand syntax is the same. What you are doing is creating an iterator object and assigning your generator function to that object.
Calling the `.next()` method on that iterator object will instruct the generator to advance from its current location to either the next `yield` (right before it), or the end of the function.
The result of that call is an object containing both a `value` (containing your immediate return value, even if it was sent out in the middle of the function's execution) and `done` (completion boolean) property.

-Iteration Messaging-
Iterators possess I/O messaging capabilities. You can actually pass a value with a `.next()` call to your iterator, and it will execute from where it left off, returning the argument passed in your `.next()` argument as the result for your `yield` expression. This even works in the middle of a statement assignment.

-Tale of Two Questions-
Remember that there is a slight mismatch in that your second `.next()` will be the one to answer the first `yield`'s request for a result value, as the first `.next()`, merely takes your function's execution from the beginning to the next yield function before pausing the iteration.
`yield` can also send messages out in response to `.next()` calls, creating a two-way messaging system.
The `.next()` call receives a value from the `yield` it stops at, and the next `.next()` can return a value back to that `yield`. You can't pass a value to the start of the function from `.next()`, only from the start of a paused `yield`. Such an action would just result in that value being silently discarded.

-Multiple Iterators-
Each constructed iterator implicitly constructs an instance of the generator that you assigned to it, and that is what the iterator controls.
Because iterators work in this fashion, you can create multiple iterators off of the same generator function, including ones that interact with one another.

-Interleaving-
Separate generators themselves can also run concurrently in the same scope and be interleaved with one another. To accomplish this, you can create a step function that takes a generator parameter, creates an iterator from that generator, and returns a function that, when called, advances the iterator of the passed generator by one step. It also takes the previously `yielded` value and returns that at the next step.
When sharing variables between multiple generators that you then iterate in varying order via the `step()` function, you can get differing resulting values. This is not the most desirable pattern to accomplish this with, as it is confusing to read and understand.

-Generator'ing Values: Producers and Iterators-
An iterator is a well-defined interface used to step through a series of values availed by a producer. This interface, in JS and many other languages, is calling `next()` each time you want to get the next value from the producer.
You can implement your own standard iterator interface by defining a function that returns an object containing your `next` method, which returns your next value as the `value` property and your iterator's completion status as the `done` boolean property.
Iterators are frequently used in the common design pattern of generating records from a data source.
You can automatically consume a standard iterator using native loop syntax with use of ES6's `for..of` loop. It will automatically call `next()` for each iteration and automatically terminate upon receiving a `done:true` property value. Be careful to add a break conditional in if your iterator never resolves to `done:true`, otherwise it will loop indefinitely.
You can also manually loop over your iterators, calling next and checking that `done` is set to false before continuing to loop. The advantage of doing it this way is that you can pass values to the `next(..)` calls if you need.
Many built-in data structures have iterators that can be looped over using `for..of`, such as `array`s. `object`s do not come with a default iterator, although you can use `Object.keys(obj)` in its place in a `for..of` loop to iterate over its (unordered) keys, similarly to `for..in`, but excluding enumerable properties from the [[Prototype]] chain.

-Iterables-
While an iterator has the `next()` method on its interface, an iterable is an `object` that contains an iterator able to iterate over its own values.
As of ES6, the way to access the iterator on an iterable is via a special function with a name equal to the ES6 symbol value of `Symbol.iterator`. Each call should return a new iterator.
When the `for..of` loop is called on an iterator, it automatically calls its `Symbol.iterator` function to construct an iterator. You can also call the function manually, and use the returned iterator to iterate and retrieve the next value.
If you have a manually defined iterator function, you can also make that function iterable by assigning a function that returns `this` to `[Symbol.iterator]` within that iterator function. Now you can pass it to a `for..of` loop, which looks for an calls that newly-added and expected iterator function, essentially passing itself back.

-Generator Iterator-
While a generator itself is not an iterable, it does return an iterator back once executed, and that iterator has a `[Symbol.iterator]` function on it, making that iterator an iterable.
You can treat generators as producers of values that can be extracted one at a time through an iterator's `next()` calls.
You can use a `while..true` loop (even without a `break` or `return`, since we pausing the generator each loop with `yield`) in a generator to produce infinite values. The state/scope of the function is preserved because the generator stays paused and waiting at each yield.
When using generators in a `for..of` loop, you want to reference the `foo()` generator function as its parameter in order to call it, which constructs a producer to generate values and avail access to its iterator interface for the loop to use to iterate over these values.

-Stopping the Generator-
Early termination or "abnormal completion' of the `for..of` loop by a `break`, `return`, or uncaught exception results in a signal being send to the generator's iterator to tell it to break.
The `for..of` loop also sends a signal at the normal completion of a loop, which is irrelevant for generators, but potentially useful for custom iterators.
You can also manually send this termination signal from your `for..of` loop to an iterator by calling `return(..)` from the loop.
When using `try..finally` inside your generator, it will always run, even when the generator is completed externally (such as in a `for..of` loop), which can be useful for clearing out used resources.
Calling `.return(..)` on an generator's iterator instance, it also immediately terminates the generator, running its `finally` clause. It will also set the return value to whatever you pass into `.return(..)`. With that, the generator's iterator instance is set to `done:true`, and the `for..of` loop will automatically terminate on its following iteration.

-Iterating Generators Asynchronously-
The `yield` used in generators allow you to have code that appears to be blocking, synchronous code, but it only pauses the code in the generator itself. The generator will only resume once the abstracted async function `yield` is waiting on completes.
Instead of passing messages with `yield`, you are using it as a means of flow control. You can still pass return messages through external functions via the `.next()` used to iterate on your generator. This means you could, for example, only iterate and pass your message when an async call successfully completes.
This means you can write reason-able code in an ordinary, sequential fashion that refers to its async elements in an abstracted manner.

-Synchronous Error Handling-
The pausing of a generator via `yield` allows for errors to be thrown to it by the called async function, catchable via `try..catch`, which normally only catches synchronous errors.
You can also catch errors coming out of a generator as well, either exception or explicitly thrown, with `try..catch`. You can even catch the same error you threw into the generator, which means you can give the generator a chance to handle the error thrown to it and then handle it it in your iterator code if unhandled in the generator.

-Generators + Promises-
The best usage of generators is to combine their readability with the composability and trustability of promises.
To do this, you would write a function that returns a promise after making an async call, and then `yield` it from the generator, receiving it from your iterator control code. The iterator itself will then take the promise resolution and either resume the generator or throw an error to it based on the presence of a fulfillment/rejection state.
Once the promise value you're yielding from your generator resolves as your iterator's `next().value`, the `.then()` for that promise is executed, handling the resolution as typical for promises, either continuing to iterate your generator or throwing it an error depending on the resolution state.

-Promise-Aware Generator Runner-
The author recommends relying upon a library utility specifically designed to run Promise-yielding generators in a way that advances them automatically, so that you don't have to repeat the code ad nauseum.
This utility method would essentially take a generator function, initialize an instance of it within the context of that function, and iterate through it. On each iteration, the utility takes the received Promise, handles it, and returns a Promise, if `it.next().done` is `false`, that asynchronously instructs then waits for the generator to iterate one more step, etcetera, on a loop. Once the iterator hits the end of the generator, the returned value is returned in a resolved Promise that wrapped the entire iteration process.

-ES7: `async` and `await`?-
Instead of directly using promises to control iteration of generators (or having to resort to a library utility to accomplish this in a recurrent manner), there is an ES7 proposal to add in `async function`s and `await` keyword.
`async function`s automatically pause themselves until the promise it is `await`ing is resolved, before advancing to the next, if any. `async function`s return their own promise once they completely finish.
This syntax is practically identical to that in C#.
Browsers and tools like Babel already make use of this feature. It appears to have been finalized for ES8.

-Promise Concurrency in Generators-
The way to fetch data from multiple sources before proceeding to the next action with generators is to keep your `yield` statements separate from your async requests, otherwise the requests will only resolve one at a time. You can separately reassign the resolved values using `yield`, after their concurrent resolution has taken place, in order to use the combined results for the next action, such as another request.
You can handle multiple requests using `Promise.all([..])` as a gate.
ES6 destructuring assignments can be used to assign your returned async results to multiple variables with just a single line of code.

-Promises, Hidden-
It's considered a best practice to minimize and abstract the Promise logic inside your generators.
Try and put those details in separate functions, so that asynchrony doesn't muddy up the higher-level expressions of the task.

-Generator Delegation-
You can call generators from other generators by calling them with the same iteration helper utility.
An easier way to do this is to use `yield` delegation syntax (simply add a `*` before the generator function identifier you are `yield`ing to).
`yield` delegation works by creating an iterator for the called generator, and then delegating the calling generator's iterator control over to the called generator's iterator. Once the iterator control finishes with that generator's iterator, it will return back to the calling generator's iterator.

-Why Delegation?-
`yield`-delegation allows for your generator/async code to remain symmetrical with normal function calling.
You will often be iterating through multiple external async generator functions, and this syntax eliminates the need for having to call upon multiple instances of the same automatic generator runner utility you're already employing from primary generator, for each generator function it `yield`s.

-Delegating Messages-
Iterators will handle messages to/from delegated generators in the same fashion as they would regular generator iteration.
You can iterate any iterable, such as arrays. Be mindful though, as the array iterator and other potential iterators do not handle messages by default.

-Excpetions Delegated, Too!-
Errors can be passed both ways between delegated `yield`s the same way as messages.
If passing an error to a `yield` delegator using your iterator control's `.throw(..)`, that `yield` will then pass (delegate) the error to the delegated generator's iterator that is currently controlled by your iterator control, to be handled by its error handler. Errors can also be returned in a similar manner.

-Delegating 'Recursion'-
You can use `yield` delegation in a recursive manner to have a generator `yield`-delegate to itself.
`yield`ed values are propagated back through the recursive call-chain, in reverse order.

-Generator Concurrency-
With generator concurrency, instead of having to sort out response array assignments manually, you can coordinate your ordering so that your responses always push in the desired sequence.
You can iterate concurrent generators (multiple instances or different generators) using a Promise-centric approach, by making your Promise-returning requests first, and then using a `.then()` chain to resume each generator instance in the desired order when their respective Promise responses are returned.
A somewhat cleaner way to accomplish this is to incorporate the use of `Promise.all(..)` to await all responses before `.then()`'ing to iterations of your generators to return or push data in the desired order.
Even better would be to create a reusable utility that performs much of the same functionality behind the scenes, concurrently initializing any promise requests, returning the resolved promise back to the `yield`ed generator that supplied it, and only resuming the proceeding generator once the one before it has completed.
You could expand such a utility even further by providing an inner variable space, such as an empty data object, to share between generator instances, and to support the ability to pass messages between generators when conducting control transfer. Such communication is the basis for an advanced async technique called Communicating Sequential Processes, or CSP.

-Thunks-
A thunk is an old concept that is expressed in JS as a function void of any parameters that calls another function that has been defined with parameters ahead of time. The wrapper function is the thunk.
For async thunks, you can add a callback function as a parameter. You'd want to write or use a utility that automatically wraps functions into thunks for you. You would provide this utility your function and arguments, and it would slice the arguments into an array and then return a function that takes a callback and returns a thunk function with those pre-defined arguments applied.
The author refers to a function that produces thunks from a thunkify utility call a "thunkory", similar to "promisory". These allow you hide your thunkification as an intermediary step, allowing you to use the thunkory to create thunks from their pre-associated function.

-s/promise/thunk-
The thunkory is comparable to the promisory in that they both pose a question (for a value), and their respective thunks/promises represent a future answer to those questions.
Because they function similarly (although not the same, as thunks don't offer the same safeguards or composability of promises), you can use them interchangably in your generators, only requiring some minor modification to your generator runner utility to call promisories or thunkories to `yield` any promises or thunks, as encountered.

-Pre-ES6 Generators-
You cannot polyfill generators in a simple manner since they are dependent on new syntax, but you can transpile the new syntax into (much messier) pre-ES6 code if need be.
`yield` can be transpiled to pre-ES6 with the use of closure-based iterators.

-Manual Transformation-
You can utilize function scope closure to emulate the behavior of suspended generator state, by declaring a state and "generator-wide" variable in the scope that closes over an inner state-handling function.
Each state is essentially every piece of code in a generator, broken down in-between the start of the generator, each yield, the end, and any sections specifically designed to handle errors.
Each time the state-handling function is called, it checks and switches to the currently-assigned state case, running the code assigned to that state (not too dissimilar from ASM game loop state handling).
Any variables that are only used by a particular state will be block-scoped to the state handler.
Each state simply replaces `yield` with a return statement, passing along any messages when necessary.
Each iteration of a transpiled generator returns an object with a boolean completion property, as well as a return value property to either be passed back into the generator, handled outside, or received as a final return at the generator's completion.

-Automatic Transpilation-
Several tools exist to transpile ES6 generators automatically, such as Facebook's regenerator.
Regenerator uses its own runner utility to manage generator iteration called `regeneratorRuntime`, and carries many similarities to the previously-outlined manual transpilation.

-Review-
Only the generator has the capability to pause itself, and only the iterator that controls it has the power to resume it (using `.next(..)`).
Generator asynchrony is hidden behind the `yield` keyword, so that any potentially asynchronous code is handled where iteration is controlled. This allows for a more synchronous style of code pattern, allowing for much greater readability than callback-oriented async code.
